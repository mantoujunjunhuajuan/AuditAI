"""AuditAI Streamlitä¸»åº”ç”¨ç¨‹åº - å¤šè¯­è¨€ç‰ˆæœ¬"""

from __future__ import annotations

import sys
import os
from pathlib import Path
from typing import List

# Ensure root directory is importable before local packages
ROOT_DIR = Path(__file__).resolve().parent.parent
if str(ROOT_DIR) not in sys.path:
    sys.path.insert(0, str(ROOT_DIR))

import streamlit as st
from dotenv import load_dotenv
from pipeline import create_pipeline
from utils.i18n import i18n

# Load environment variables from .env file
load_dotenv()

# ---------------------------------------------------------------------------
# Streamlit page config and main app logic
# ---------------------------------------------------------------------------

def setup_page():
    """é…ç½®é¡µé¢åŸºæœ¬è®¾ç½®"""
    st.set_page_config(
        page_title="AuditAI - æ™ºèƒ½ä¿é™©ç†èµ”å®¡æ ¸ç³»ç»Ÿ",
        page_icon="ğŸ”",
        layout="wide"
    )

def render_language_switcher():
    """æ¸²æŸ“è¯­è¨€åˆ‡æ¢å™¨"""
    st.sidebar.markdown("---")
    st.sidebar.markdown("### ğŸŒ Language / è¯­è¨€")
    
    current_lang = i18n.get_current_language()
    
    col1, col2 = st.sidebar.columns(2)
    
    with col1:
        if st.button(
            i18n.get_text("language.switch_to_chinese"), 
            disabled=(current_lang == 'zh'),
            use_container_width=True
        ):
            i18n.set_language('zh')
            st.rerun()
    
    with col2:
        if st.button(
            i18n.get_text("language.switch_to_english"), 
            disabled=(current_lang == 'en'),
            use_container_width=True
        ):
            i18n.set_language('en')
            st.rerun()

def check_api_key():
    """æ£€æŸ¥APIå¯†é’¥é…ç½®"""
    api_key = os.getenv("GEMINI_API_KEY")
    
    with st.sidebar:
        st.markdown(f"### {i18n.get_text('api_config.title')}")
        
        if not api_key:
            st.warning(i18n.get_text('api_config.warning'))
            st.info(i18n.get_text('api_config.info'))
            return False
        else:
            st.success(i18n.get_text('api_config.success'))
            return True

def check_storage_service():
    """æ£€æŸ¥å¹¶æ˜¾ç¤ºå­˜å‚¨æœåŠ¡é…ç½®"""
    gcs_bucket = os.getenv("GCS_BUCKET")
    
    with st.sidebar:
        st.markdown("### â˜ï¸ Storage Configuration")
        
        if gcs_bucket:
            st.success(f"âœ… {i18n.get_text('storage.gcs_title')}")
            st.info(i18n.get_text('storage.gcs_bucket', bucket=gcs_bucket))
            st.markdown(i18n.get_text('storage.gcs_description'))
            return "gcs"
        else:
            st.info(i18n.get_text('storage.local_title'))
            st.markdown(i18n.get_text('storage.local_description'))
            return "local"

def render_processing_steps():
    """æ¸²æŸ“å¤„ç†æ­¥éª¤è¯´æ˜"""
    st.markdown(i18n.get_text('processing_steps.title'))
    st.markdown(i18n.get_text('processing_steps.step1'))
    st.markdown(i18n.get_text('processing_steps.step2'))
    st.markdown(i18n.get_text('processing_steps.step3'))
    st.markdown(i18n.get_text('processing_steps.step4'))
    st.markdown(i18n.get_text('processing_steps.step5'))

def get_risk_level_text(risk_score):
    """æ ¹æ®é£é™©è¯„åˆ†è·å–é£é™©ç­‰çº§æ–‡æœ¬"""
    if risk_score >= 75:
        return i18n.get_text('metrics.critical_risk')
    elif risk_score >= 50:
        return i18n.get_text('metrics.high_risk')
    elif risk_score >= 25:
        return i18n.get_text('metrics.medium_risk')
    else:
        return i18n.get_text('metrics.low_risk')

def get_file_type_info(file):
    """è·å–æ–‡ä»¶ç±»å‹ä¿¡æ¯å’Œå¤„ç†å»ºè®®"""
    file_extension = file.name.lower().split('.')[-1] if '.' in file.name else ''
    
    file_types = {
        'pdf': {
            'icon': 'ğŸ“„',
            'type': 'PDF Document',
            'type_zh': 'PDFæ–‡æ¡£',
            'category': 'document',
            'processing_note': 'Standard text extraction and analysis',
            'processing_note_zh': 'æ ‡å‡†æ–‡æœ¬æå–å’Œåˆ†æ'
        },
        'jpg': {'icon': 'ğŸ–¼ï¸', 'type': 'JPEG Image', 'type_zh': 'JPEGå›¾åƒ', 'category': 'image'},
        'jpeg': {'icon': 'ğŸ–¼ï¸', 'type': 'JPEG Image', 'type_zh': 'JPEGå›¾åƒ', 'category': 'image'},
        'png': {'icon': 'ğŸ–¼ï¸', 'type': 'PNG Image', 'type_zh': 'PNGå›¾åƒ', 'category': 'image'},
        'tiff': {'icon': 'ğŸ¥', 'type': 'Medical Imaging (TIFF)', 'type_zh': 'åŒ»ç–—å½±åƒ(TIFF)', 'category': 'medical_image'},
        'tif': {'icon': 'ğŸ¥', 'type': 'Medical Imaging (TIFF)', 'type_zh': 'åŒ»ç–—å½±åƒ(TIFF)', 'category': 'medical_image'},
        'dcm': {'icon': 'ğŸ©»', 'type': 'DICOM Medical Image', 'type_zh': 'DICOMåŒ»ç–—å½±åƒ', 'category': 'dicom'},
        'doc': {'icon': 'ğŸ“', 'type': 'Word Document', 'type_zh': 'Wordæ–‡æ¡£', 'category': 'document'},
        'docx': {'icon': 'ğŸ“', 'type': 'Word Document', 'type_zh': 'Wordæ–‡æ¡£', 'category': 'document'},
        'bmp': {'icon': 'ğŸ–¼ï¸', 'type': 'Bitmap Image', 'type_zh': 'ä½å›¾å›¾åƒ', 'category': 'image'}
    }
    
    current_lang = i18n.get_current_language()
    file_info = file_types.get(file_extension, {
        'icon': 'ğŸ“',
        'type': 'Unknown File',
        'type_zh': 'æœªçŸ¥æ–‡ä»¶',
        'category': 'unknown'
    })
    
    # ä¸ºä¸åŒç±»å‹çš„æ–‡ä»¶æ·»åŠ å¤„ç†è¯´æ˜
    if file_info['category'] == 'image' or file_info['category'] == 'medical_image':
        file_info['processing_note'] = 'OCR text extraction and image analysis'
        file_info['processing_note_zh'] = 'OCRæ–‡æœ¬æå–å’Œå›¾åƒåˆ†æ'
    elif file_info['category'] == 'dicom':
        file_info['processing_note'] = 'Medical imaging metadata and visual analysis'
        file_info['processing_note_zh'] = 'åŒ»ç–—å½±åƒå…ƒæ•°æ®å’Œè§†è§‰åˆ†æ'
    elif file_info['category'] == 'document':
        file_info['processing_note'] = 'Document parsing and content extraction'
        file_info['processing_note_zh'] = 'æ–‡æ¡£è§£æå’Œå†…å®¹æå–'
    
    return file_info

def render_progress_tracker(steps_status):
    """æ¸²æŸ“è¿›åº¦è¿½è¸ªå™¨"""
    st.markdown(f"### {i18n.get_text('processing.progress_title')}")
    
    steps = [
        ("doc_analysis", i18n.get_text('steps.doc_analysis')),
        ("info_extraction", i18n.get_text('steps.info_extraction')),
        ("rule_check", i18n.get_text('steps.rule_check')),
        ("risk_analysis", i18n.get_text('steps.risk_analysis')),
        ("report_generation", i18n.get_text('steps.report_generation'))
    ]
    
    cols = st.columns(5)
    for i, (step_key, step_name) in enumerate(steps):
        with cols[i]:
            status = steps_status.get(step_key, "pending")
            if status == "completed":
                st.markdown(f"{i18n.get_text('steps.completed')} **{step_name}**")
            elif status == "processing":
                st.markdown(f"{i18n.get_text('steps.processing')} **{step_name}**")
            else:
                st.markdown(f"{i18n.get_text('steps.pending')} **{step_name}**")

def main():
    """ä¸»åº”ç”¨ç¨‹åº"""
    setup_page()
    
    # ä¸»æ ‡é¢˜
    st.title("ğŸ” AuditAI - æ™ºèƒ½ä¿é™©ç†èµ”å®¡æ ¸ç³»ç»Ÿ")
    st.markdown("---")

    # ä¾§è¾¹æ é…ç½®
    st.sidebar.header("âš™ï¸ ç³»ç»Ÿé…ç½®")

    # è¯­è¨€é€‰æ‹©
    language_display = st.sidebar.selectbox(
        "ğŸŒ è¯­è¨€ / Language",
        ["ä¸­æ–‡", "English"],
        key="language_display"
    )
    
    # æ˜ å°„æ˜¾ç¤ºè¯­è¨€åˆ°ä»£ç 
    language_map = {"ä¸­æ–‡": "zh", "English": "en"}
    current_language_code = language_map[language_display]
    
    # æ›´æ–°i18nè¯­è¨€è®¾ç½®
    if i18n.get_current_language() != current_language_code:
        i18n.set_language(current_language_code)

    # æ¨¡å‹é€‰æ‹©
    st.sidebar.subheader("ğŸ¤– AIæ¨¡å‹é…ç½®")
    model_choice = st.sidebar.selectbox(
        "é€‰æ‹©Geminiæ¨¡å‹ / Choose Gemini Model",
        [
            "gemini-1.5-flash (æ¨è/Recommended)",
            "gemini-1.5-pro (é«˜è´¨é‡/High Quality)", 
            "gemini-1.0-pro (å…¼å®¹æ€§æœ€ä½³/Best Compatibility)",
            "gemini-2.5-flash (æœ€æ–°/Latest)"
        ],
        key="model_choice",
        help="ä¸åŒæ¨¡å‹åœ¨ä¸åŒåœ°åŒºçš„å¯ç”¨æ€§å¯èƒ½ä¸åŒ / Model availability may vary by region"
    )

    # æå–æ¨¡å‹åç§°
    model_mapping = {
        "gemini-1.5-flash (æ¨è/Recommended)": "gemini-1.5-flash",
        "gemini-1.5-pro (é«˜è´¨é‡/High Quality)": "gemini-1.5-pro", 
        "gemini-1.0-pro (å…¼å®¹æ€§æœ€ä½³/Best Compatibility)": "gemini-1.0-pro",
        "gemini-2.5-flash (æœ€æ–°/Latest)": "gemini-2.5-flash"
    }
    selected_model = model_mapping[model_choice]

    # æ˜¾ç¤ºå½“å‰æ¨¡å‹çŠ¶æ€å’Œæµ‹è¯•åŠŸèƒ½
    with st.sidebar:
        st.info(f"å½“å‰æ¨¡å‹: {selected_model}")
        
        # æ¨¡å‹æµ‹è¯•åŠŸèƒ½
        if st.button("ğŸ§ª æµ‹è¯•æ¨¡å‹ / Test Model", help="æµ‹è¯•æ‰€é€‰æ¨¡å‹æ˜¯å¦åœ¨å½“å‰åœ°åŒºå¯ç”¨"):
            with st.spinner("æµ‹è¯•æ¨¡å‹è¿æ¥..."):
                try:
                    from services.gemini_client import GeminiClient
                    test_client = GeminiClient(model=selected_model)
                    test_result = test_client.generate_content(prompt="Hello")
                    st.success(f"âœ… æ¨¡å‹ {selected_model} å¯ç”¨ï¼")
                    st.caption(f"å“åº”é•¿åº¦: {len(test_result)} å­—ç¬¦")
                except Exception as e:
                    if "User location is not supported" in str(e):
                        st.error(f"âŒ åœ°ç†ä½ç½®é™åˆ¶: {selected_model} åœ¨å½“å‰åœ°åŒºä¸å¯ç”¨")
                        st.warning("å»ºè®®é€‰æ‹©å…¶ä»–æ¨¡å‹æˆ–ä½¿ç”¨VPN")
                    else:
                        st.error(f"âŒ æ¨¡å‹æµ‹è¯•å¤±è´¥: {str(e)}")
                        st.info("è¯·æ£€æŸ¥APIå¯†é’¥æˆ–ç½‘ç»œè¿æ¥")

    # æ¸²æŸ“è¯­è¨€åˆ‡æ¢å™¨
    render_language_switcher()
    
    # æ ‡é¢˜å’Œæè¿°
    st.title(i18n.get_text('page_title'))
    st.markdown(i18n.get_text('page_description'))
    
    # æ£€æŸ¥APIå¯†é’¥
    if not check_api_key():
        st.error(i18n.get_text('file_upload.error_no_key'))
        return
    
    # æ£€æŸ¥å­˜å‚¨æœåŠ¡é…ç½®
    storage_type = check_storage_service()
    
    # å¤„ç†æ­¥éª¤è¯´æ˜
    render_processing_steps()
    
    # æ–‡ä»¶ä¸Šä¼  - æ”¯æŒä¿é™©ç†èµ”å¸¸è§æ–‡ä»¶æ ¼å¼
    uploaded_file = st.file_uploader(
        i18n.get_text('file_upload.label'), 
        type=['pdf', 'png', 'jpg', 'jpeg', 'tiff', 'tif', 'bmp', 'dcm', 'doc', 'docx'],
        help=i18n.get_text('file_upload.help_text')
    )
    
    if uploaded_file is not None:
        # æ˜¾ç¤ºæ–‡ä»¶ä¿¡æ¯å’Œç±»å‹è¯†åˆ«
        file_size = len(uploaded_file.getvalue()) / (1024 * 1024)  # MB
        file_info = get_file_type_info(uploaded_file)
        current_lang = i18n.get_current_language()
        
        # æ˜¾ç¤ºæ–‡ä»¶åŸºæœ¬ä¿¡æ¯
        st.info(i18n.get_text('file_upload.info', filename=uploaded_file.name, size=file_size))
        
        # æ˜¾ç¤ºæ–‡ä»¶ç±»å‹å’Œå¤„ç†æ–¹å¼
        col1, col2 = st.columns([1, 3])
        with col1:
            st.markdown(f"**{file_info['icon']} æ–‡ä»¶ç±»å‹**" if current_lang == 'zh' else f"**{file_info['icon']} File Type**")
        with col2:
            file_type_text = file_info['type_zh'] if current_lang == 'zh' else file_info['type']
            processing_note = file_info.get('processing_note_zh' if current_lang == 'zh' else 'processing_note', '')
            st.markdown(f"**{file_type_text}**")
            if processing_note:
                st.caption(f"ğŸ”§ {processing_note}")
        
        # ä¸ºéPDFæ–‡ä»¶æ˜¾ç¤ºç‰¹æ®Šå¤„ç†è¯´æ˜
        if file_info['category'] != 'document':
            if current_lang == 'zh':
                st.warning("âš ï¸ æ³¨æ„ï¼šå›¾åƒå’ŒåŒ»ç–—å½±åƒæ–‡ä»¶å°†é€šè¿‡OCRå’ŒAIè§†è§‰åˆ†æè¿›è¡Œå¤„ç†ï¼Œå¤„ç†æ—¶é—´å¯èƒ½è¾ƒé•¿ã€‚")
            else:
                st.warning("âš ï¸ Note: Image and medical imaging files will be processed through OCR and AI visual analysis, which may take longer.")
        
        # å¼€å§‹å¤„ç†æŒ‰é’®
        if st.button(i18n.get_text('file_upload.button'), type="primary"):
            
            try:
                # åˆå§‹åŒ–æ­¥éª¤çŠ¶æ€
                steps_status = {
                    "doc_analysis": "pending",
                    "info_extraction": "pending", 
                    "rule_check": "pending",
                    "risk_analysis": "pending",
                    "report_generation": "pending"
                }
                
                # Create the complete pipeline with selected model
                with st.spinner(i18n.get_text('processing.initializing')):
                    pipeline = create_pipeline(model=selected_model)
                    storage_service = pipeline.storage_service
                
                # ä¸Šä¼ æ–‡ä»¶åˆ°å­˜å‚¨æœåŠ¡
                with st.spinner(i18n.get_text('processing.uploading')):
                    file_path = storage_service.save_uploaded_file(uploaded_file, uploaded_file.name)
                    
                    # Display success message based on storage type
                    if storage_type == "gcs":
                        st.success(i18n.get_text('storage.uploaded_to_gcs'))
                        st.info(i18n.get_text('storage.gcs_location', location=f"gs://{os.getenv('GCS_BUCKET')}/claims/{uploaded_file.name}"))
                        st.markdown(i18n.get_text('storage.powered_by_gcp'))
                    else:
                        st.success(i18n.get_text('processing.uploaded', filename=uploaded_file.name))
                
                # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ–‡æœ¬
                progress_bar = st.progress(0)
                status_text = st.empty()
                
                # æ¸²æŸ“æ­¥éª¤è¿½è¸ªå™¨
                steps_container = st.container()
                
                # 1. æ–‡æ¡£åˆ†æ
                steps_status["doc_analysis"] = "processing"
                with steps_container:
                    render_progress_tracker(steps_status)
                
                progress_bar.progress(20)
                status_text.text(i18n.get_text('processing.doc_analysis'))
                
                try:
                    doc_output = pipeline.doc_intel_agent.process(file_path)
                    steps_status["doc_analysis"] = "completed"
                except Exception as e:
                    st.error(f"ğŸ“„ æ–‡æ¡£åˆ†æå¤±è´¥: {str(e)}")
                    st.warning("è¯·æ£€æŸ¥æ–‡æ¡£æ ¼å¼æ˜¯å¦ä¸ºæ ‡å‡†PDFæ–‡ä»¶")
                    steps_status["doc_analysis"] = "failed"
                    return
                
                # 2. ä¿¡æ¯æå–
                steps_status["info_extraction"] = "processing"
                with steps_container:
                    render_progress_tracker(steps_status)
                    
                progress_bar.progress(40)
                status_text.text(i18n.get_text('processing.info_extraction'))
                
                try:
                    extraction_output = pipeline.info_extract_agent.process(doc_output)
                    steps_status["info_extraction"] = "completed"
                except Exception as e:
                    st.error(f"ğŸ” ä¿¡æ¯æå–å¤±è´¥: {str(e)}")
                    st.warning("AIæœåŠ¡å¯èƒ½æš‚æ—¶ç¹å¿™ï¼Œè¯·ç¨åé‡è¯•")
                    steps_status["info_extraction"] = "failed"
                    return
                
                # 3. è§„åˆ™éªŒè¯
                steps_status["rule_check"] = "processing"
                with steps_container:
                    render_progress_tracker(steps_status)
                    
                progress_bar.progress(60)
                status_text.text(i18n.get_text('processing.rule_validation'))
                
                try:
                    validation_result = pipeline.rule_check_agent.process(extraction_output)
                    steps_status["rule_check"] = "completed"
                except Exception as e:
                    st.error(f"ğŸ“‹ è§„åˆ™éªŒè¯å¤±è´¥: {str(e)}")
                    st.warning("éªŒè¯è§„åˆ™å¯èƒ½éœ€è¦æ›´æ–°ï¼Œç»§ç»­ä½¿ç”¨åŸºç¡€éªŒè¯")
                    # åˆ›å»ºä¸€ä¸ªåŸºç¡€çš„éªŒè¯ç»“æœä½œä¸ºfallback
                    from agents.rule_check import RuleValidationResult
                    validation_result = RuleValidationResult(is_valid=True, violations=[], warnings=[])
                    steps_status["rule_check"] = "completed_with_warnings"
                
                # 4. é£é™©åˆ†æ (å¤šæ™ºèƒ½ä½“åä½œ)
                steps_status["risk_analysis"] = "processing"
                with steps_container:
                    render_progress_tracker(steps_status)
                    
                progress_bar.progress(80)
                status_text.text(i18n.get_text('processing.risk_analysis'))
                
                try:
                    risk_analysis_output = pipeline.risk_analysis_agent.process(
                        extraction_output, 
                        validation_result,
                        doc_intel_output=doc_output,  # Enable collaboration
                        info_extract_agent=pipeline.info_extract_agent
                    )
                    steps_status["risk_analysis"] = "completed"
                except Exception as e:
                    st.error(f"âš ï¸ é£é™©åˆ†æå¤±è´¥: {str(e)}")
                    st.warning("AIé£é™©è¯„ä¼°æœåŠ¡å¼‚å¸¸ï¼Œä½¿ç”¨åŸºç¡€é£é™©è¯„ä¼°")
                    # åˆ›å»ºä¸€ä¸ªåŸºç¡€çš„é£é™©åˆ†æç»“æœä½œä¸ºfallback
                    from agents.risk_analysis import RiskAnalysisOutput
                    risk_analysis_output = RiskAnalysisOutput(
                        risk_score=50,
                        risk_factors=["AIæœåŠ¡å¼‚å¸¸ï¼ŒåŸºç¡€è¯„ä¼°"],
                        fraud_indicators=[],
                        processing_priority="Standard",
                        siu_referral=False,
                        auto_approve_eligible=False
                    )
                    steps_status["risk_analysis"] = "completed_with_warnings"
                
                # 5. æŠ¥å‘Šç”Ÿæˆ
                steps_status["report_generation"] = "processing"
                with steps_container:
                    render_progress_tracker(steps_status)
                    
                progress_bar.progress(90)
                status_text.text(i18n.get_text('processing.report_generation'))
                
                try:
                    # Get current language for localized report generation
                    current_lang = i18n.get_current_language()
                    final_report = pipeline.report_gen_agent.process(risk_analysis_output, extraction_output.extracted_data, current_lang)
                    steps_status["report_generation"] = "completed"
                except Exception as e:
                    st.error(f"ğŸ“Š æŠ¥å‘Šç”Ÿæˆå¤±è´¥: {str(e)}")
                    st.warning("ä½¿ç”¨åŸºç¡€æŠ¥å‘Šæ¨¡æ¿")
                    # åˆ›å»ºä¸€ä¸ªåŸºç¡€çš„æŠ¥å‘Šä½œä¸ºfallback
                    from agents.report_gen import ReportOutput
                    final_report = ReportOutput(
                        recommendation="Manual_Review",
                        confidence_score=0.5,
                        report_content=f"""
# åŸºç¡€å®¡è®¡æŠ¥å‘Š

## æ–‡æ¡£åˆ†æ
- æ–‡æ¡£ç±»å‹: {getattr(doc_output, 'document_type', 'æœªçŸ¥')}
- å¤„ç†çŠ¶æ€: éƒ¨åˆ†å¤„ç†å®Œæˆ

## é£é™©è¯„ä¼°
- é£é™©è¯„åˆ†: {risk_analysis_output.risk_score}/100
- å¤„ç†å»ºè®®: äººå·¥å®¡æ ¸

## æ³¨æ„äº‹é¡¹
- AIæœåŠ¡éƒ¨åˆ†å¼‚å¸¸ï¼Œå»ºè®®äººå·¥å¤æ ¸
- æŠ¥å‘ŠåŸºäºå¯ç”¨ä¿¡æ¯ç”Ÿæˆ

**å»ºè®®**: è”ç³»æŠ€æœ¯æ”¯æŒæˆ–é‡æ–°ä¸Šä¼ æ–‡æ¡£
                        """,
                        source_uri=getattr(doc_output, 'source_uri', file_path),
                        processing_priority="Standard",
                        investigation_required=False,
                        next_actions=["äººå·¥å®¡æ ¸", "æŠ€æœ¯æ”¯æŒ", "é‡æ–°æäº¤"]
                    )
                    steps_status["report_generation"] = "completed_with_warnings"
                
                # å®Œæˆ
                progress_bar.progress(100)
                status_text.text(i18n.get_text('processing.completed'))
                
                with steps_container:
                    render_progress_tracker(steps_status)
                
                st.success(i18n.get_text('processing.completed'))
                
                # æ˜¾ç¤ºç»“æœ
                st.markdown("---")
                st.markdown("## ğŸ¯ **Analysis Results / åˆ†æç»“æœ**")
                
                # Enhanced summary metrics with multi-language support
                col1, col2, col3, col4 = st.columns(4)
                
                with col1:
                    risk_level = get_risk_level_text(risk_analysis_output.risk_score)
                    st.metric(
                        label=i18n.get_text('metrics.risk_score'),
                        value=f"{risk_analysis_output.risk_score}/100",
                        delta=risk_level
                    )
                
                with col2:
                    priority_text = i18n.get_priority_text(risk_analysis_output.processing_priority)
                    st.metric(
                        label=i18n.get_text('metrics.processing_priority'),
                        value=priority_text
                    )
                
                with col3:
                    siu_text = i18n.get_text('metrics.needed') if risk_analysis_output.siu_referral else i18n.get_text('metrics.not_needed')
                    st.metric(
                        label=i18n.get_text('metrics.siu_investigation'),
                        value=siu_text
                    )
                
                with col4:
                    recommendation_text = i18n.get_recommendation_text(final_report.recommendation)
                    st.metric(
                        label=i18n.get_text('metrics.final_recommendation'),
                        value=recommendation_text,
                        delta=f"{i18n.get_text('metrics.confidence')}: {final_report.confidence_score:.0%}"
                    )
                
                # Enhanced detailed results with North American standards
                tab1, tab2, tab3, tab4, tab5 = st.tabs([
                    i18n.get_text('tabs.final_report'),
                    i18n.get_text('tabs.fraud_analysis'), 
                    i18n.get_text('tabs.extracted_info'),
                    i18n.get_text('tabs.detailed_analysis'),
                    i18n.get_text('tabs.technical_details')
                ])
                
                with tab1:
                    st.markdown(f"### {i18n.get_text('tabs.final_report')}")
                    st.markdown(final_report.report_content)
                
                with tab2:
                    st.markdown(f"### {i18n.get_text('fraud_analysis.title')}")
                    
                    # Processing Priority Indicators
                    if risk_analysis_output.processing_priority == "Expedited":
                        st.success(i18n.get_text('fraud_analysis.expedited_processing'))
                    elif risk_analysis_output.processing_priority == "Enhanced_Review":
                        st.error(i18n.get_text('fraud_analysis.enhanced_review'))
                    else:
                        st.info(i18n.get_text('fraud_analysis.standard_processing'))
                    
                    # SIU Investigation
                    if risk_analysis_output.siu_referral:
                        st.error(f"**{i18n.get_text('fraud_analysis.siu_required')}**")
                        st.markdown(i18n.get_text('fraud_analysis.siu_description'))
                    else:
                        st.success(i18n.get_text('fraud_analysis.no_siu'))
                    
                    # Auto-approval eligibility
                    if risk_analysis_output.auto_approve_eligible:
                        st.success(f"**{i18n.get_text('fraud_analysis.auto_approve_eligible')}**")
                        st.markdown(i18n.get_text('fraud_analysis.auto_approve_description'))
                    else:
                        st.warning(f"**{i18n.get_text('fraud_analysis.manual_review_required')}**")
                        st.markdown(i18n.get_text('fraud_analysis.manual_review_description'))
                    
                    # Fraud indicators
                    st.markdown(i18n.get_text('fraud_analysis.fraud_indicators'))
                    if risk_analysis_output.fraud_indicators:
                        for indicator in risk_analysis_output.fraud_indicators:
                            st.warning(f"ğŸš¨ {indicator}")
                    else:
                        st.success(i18n.get_text('fraud_analysis.no_fraud_detected'))
                    
                    # Settlement estimate
                    if hasattr(risk_analysis_output, 'settlement_estimate') and risk_analysis_output.settlement_estimate:
                        st.markdown(i18n.get_text('fraud_analysis.settlement_estimate'))
                        st.info(f"ğŸ’° {risk_analysis_output.settlement_estimate}")
                
                with tab3:
                    st.markdown(f"### {i18n.get_text('tabs.extracted_info')}")
                    st.json(extraction_output.extracted_data)
                
                with tab4:
                    st.markdown(f"### {i18n.get_text('detailed_analysis.title')}")
                    
                    st.markdown(i18n.get_text('detailed_analysis.rule_validation'))
                    if validation_result.violations:
                        for violation in validation_result.violations:
                            st.error(f"âŒ {violation}")
                    else:
                        st.success(i18n.get_text('detailed_analysis.all_rules_passed'))
                    
                    st.markdown(i18n.get_text('detailed_analysis.risk_factors'))
                    if risk_analysis_output.risk_factors:
                        for factor in risk_analysis_output.risk_factors:
                            st.warning(f"âš ï¸ {factor}")
                    else:
                        st.success(i18n.get_text('detailed_analysis.no_risk_factors'))
                    
                    # Next actions
                    if hasattr(final_report, 'next_actions') and final_report.next_actions:
                        st.markdown(i18n.get_text('detailed_analysis.next_actions'))
                        for action in final_report.next_actions:
                            st.info(f"ğŸ“‹ {action}")
                
                with tab5:
                    st.markdown(f"### {i18n.get_text('technical_details.title')}")
                    
                    tech_data = {
                        i18n.get_text('technical_details.document_type'): doc_output.document_type,
                        i18n.get_text('technical_details.content_length'): f"{len(doc_output.extracted_text)} {i18n.get_text('technical_details.characters')}",
                        i18n.get_text('technical_details.validation_status'): "âœ…" if not validation_result.violations else "âŒ",
                        i18n.get_text('technical_details.risk_score'): f"{risk_analysis_output.risk_score}/100",
                        i18n.get_text('technical_details.processing_model'): selected_model,
                        i18n.get_text('technical_details.file_uri'): file_path
                    }
                    
                    for key, value in tech_data.items():
                        st.text(f"{key}: {value}")
            
            except Exception as e:
                st.error(i18n.get_text('errors.processing_error', error=str(e)))
                st.error(f"Traceback: {str(e)}")
    
    # é¡µè„š
    st.markdown("---")
    st.markdown(f"<center>{i18n.get_text('footer')}</center>", unsafe_allow_html=True)

if __name__ == "__main__":
    main()