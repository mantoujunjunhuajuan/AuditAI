"""Gemini (Generative Language) client wrapper.

Handles authentication via environment variable ``GEMINI_API_KEY``.
Wraps the Google Generative AI Python SDK and provides simple generate_content
helper with basic retry/backoff.

NOTE: Requires ``google-generativeai`` package.
"""

from __future__ import annotations

import os
from typing import Any

import google.generativeai as genai
from tenacity import retry, stop_after_attempt, wait_exponential

API_KEY_ENV = "GEMINI_API_KEY"


class GeminiClient:
    """A client for interacting with the Gemini API using the google-generativeai SDK."""

    def __init__(self, api_key: str | None = None, model: str | None = None) -> None:
        """Initializes the Gemini client.

        Args:
            api_key: The API key for the Gemini API. If not provided, it will
              be read from the GEMINI_API_KEY environment variable.
            model: The Gemini model to use. If not provided, it will default
              to 'gemini-1.5-flash' (widely supported).
        """
        self.api_key = api_key or os.environ.get(API_KEY_ENV)
        if not self.api_key:
            raise RuntimeError(f"Environment variable {API_KEY_ENV} is required for Gemini access")

        # Configure the API key
        genai.configure(api_key=self.api_key)
        
        # Set the model name - use globally supported model as default
        self.model_name = model or "gemini-1.5-flash"
        
        # Initialize the model
        try:
            self.model = genai.GenerativeModel(self.model_name)
            print(f"âœ… Gemini client initialized with model: {self.model_name}")
        except Exception as e:
            print(f"âŒ Failed to initialize Gemini model '{self.model_name}': {e}")
            # Try fallback models in order of preference
            fallback_models = ["gemini-1.5-pro", "gemini-1.0-pro"]
            
            for fallback_model in fallback_models:
                try:
                    self.model_name = fallback_model
                    self.model = genai.GenerativeModel(self.model_name)
                    print(f"âœ… Fallback to model: {self.model_name}")
                    break
                except Exception as e2:
                    print(f"âŒ Fallback model '{fallback_model}' also failed: {e2}")
                    continue
            else:
                raise RuntimeError(f"Failed to initialize any Gemini model. Last error: {e}")

    @retry(wait=wait_exponential(multiplier=1, min=1, max=10), stop=stop_after_attempt(3))
    def generate_content(self, *, prompt: str, **kwargs: Any) -> str:
        """Generate text content using Gemini model with retries."""
        try:
            print(f"ğŸ¤– Calling Gemini API with model: {self.model_name}")
            response = self.model.generate_content(prompt, **kwargs)
            
            if not response.text:
                raise RuntimeError("Gemini API returned empty response")
                
            print(f"âœ… Gemini API call successful, response length: {len(response.text)} characters")
            return response.text
            
        except Exception as err:
            print(f"âŒ Gemini API call failed: {err}")
            
            # å¦‚æœæ˜¯åœ°ç†ä½ç½®é™åˆ¶é”™è¯¯ï¼Œæä¾›æ˜ç¡®çš„é”™è¯¯ä¿¡æ¯
            if "User location is not supported" in str(err):
                error_msg = (
                    f"Gemini APIåœ°ç†ä½ç½®é™åˆ¶é”™è¯¯: {err}\n\n"
                    "å»ºè®®è§£å†³æ–¹æ¡ˆ:\n"
                    "1. ä½¿ç”¨æ”¯æŒåœ°åŒºçš„VPNæœåŠ¡\n"
                    "2. è”ç³»Google Cloudæ”¯æŒç”³è¯·åœ°åŒºè®¿é—®æƒé™\n"
                    "3. è€ƒè™‘éƒ¨ç½²åˆ°æ”¯æŒçš„Google Cloudåœ°åŒº\n"
                    "4. ä½¿ç”¨å…¶ä»–AIæœåŠ¡æä¾›å•†çš„API"
                )
                raise RuntimeError(error_msg) from err
            
            # å…¶ä»–é”™è¯¯ç›´æ¥æŠ›å‡º
            error_msg = f"Gemini API call failed with model '{self.model_name}': {err}"
            raise RuntimeError(error_msg) from err 